\documentclass[12pt]{article}

\usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb}
\usepackage{enumitem}
%\usepackage{minted}
\usepackage[unicode,hidelinks]{hyperref}
\usepackage{textcomp}
\usepackage{diagbox}
\usepackage[pdftex]{graphicx}
\usepackage{pdfpages}
\graphicspath{{images/}, {.}}

\usepackage{wrapfig}
\usepackage{cite} 
 
\usepackage{multirow}

\newcommand{\inp}[2]{\langle#1, #2\rangle}

\usepackage{subcaption}
\usepackage{longtable}
\usepackage{tabularx}
\usepackage{ltablex}


\usepackage{algorithm, algorithmicx, algpseudocode}

\usepackage{cmap}
\usepackage[T2A,T1]{fontenc} 
\usepackage[utf8]{inputenc} 
\usepackage[english,russian]{babel}

\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand*{\logequiv}{\ \Longleftrightarrow \ }
\newcommand*\mean[1]{\overline{#1}}

%\renewcommand{\arraystretch}{1.5}
\linespread{1.3} % Полуторный интервал
%\pagestyle{plain}

\usepackage{booktabs}
\usepackage{makecell}

\usepackage{mathtools}

\newenvironment{itemize*}%
{\begin{itemize}%
		\setlength{\itemsep}{0pt}%
		\setlength{\parskip}{0pt}}%
	{\end{itemize}}

\newenvironment{enumerate*}%
{\begin{enumerate}%
		\setlength{\itemsep}{0pt}%
		\setlength{\parskip}{0pt}}%
	{\end{enumerate}}

\newcommand{\hrefl}[1] {\texttt{\href{#1}{#1}}}
\renewcommand{\epsilon}{\varepsilon}
\renewcommand{\phi}{\varphi}

\begin{document}

%\includepdf{titlepage.pdf}

\title{Метод обобщения в таксономиях и его применение}
\author{Власов Александр Сергеевич}
\date{}
\maketitle
\tableofcontents

\section{Введение}
% спостановка задач и объяснение того, что до меня никто это не делал

% ==============================================================================
\section{Метод обобщения}

% ------------------------------------------------------------------------------
\subsection{Модель обобщения в таксономии}

С математической точки зрения таксономия --- это корневое дерево, вершины которого аннотированы различными понятиями (темами) предметной области. Рассмотрим следующую задачу. Дано нечеткое множество $S$, элементы которого являются листьями таксономии. Необходимо найти вершину более высокого уровня $t(S)$ (головное понятие, головная тема, head subject), которая как можно более плотно покрывает множество $S$. Подобная задача "<подъема"> --- это математически заданная модель способности человека к обобщению информации. При этом обобщаемые концепты заданы нечетким множеством на листьях таксономии.

Формальная постановка задачи обобщения разработана Б.Миркиным, Т.Феннером и др. в \cite{mirkin2003algorithms} в приложении к эволюционной биологии. Была сформулирована и предпринята попытка решения задачи определения оптимального сценария переноса (потери и приобретения) генов на эволюционном дереве организмов. Дальнейшее развитие метод получил в \cite{mirkin2006aggregating}, где применялся так же к задаче биологии, и в \cite{mirkin2018preprint}, где метод был применен к задаче структуризации и концептуализации коллекции научных текстов.
%%%is not as simple ...?

Приведем основные понятия, необходимые для постановки задачи. При подъеме множества $S$ может возникнуть два типа ошибок --- пробелы (gap) и выбросы (offshoot). На рис. \ref{fig:gap_offshoot_example} показан пример обобщения множества, выделенного серым цветом, одним головным понятием. На рисунке четко видны два типа ошибок:
\begin{itemize*}
	\item Пробел ---  лист, не принадлежащий исходному множеству, но попавший в часть дерева, лежащую под головным понятием.
	\item Выброс --- лист, который остался непокрытым головным понятием несмотря на то, что он принадлежал исходному множеству. 
\end{itemize*} 

\begin{figure}
\centering
\includegraphics[width=0.5\linewidth]{images/gap_offshoot_example}
\caption{Обобщение множества, выделенного серыми цветом на таксономии. Указано головное понятие и два типа ошибок.}
\label{fig:gap_offshoot_example}
\end{figure}

В терминах задачи классификации пробел --- это  ошибка первого рода (false positive), выброс --- ошибка второго рода (false negative). 

Один из способов способ обобщить множество --- взять в качестве головного понятия последнюю (наиболеее глубокую) вершину, которая является предком для каждой из вершин во множестве. Несмотря на простоту этого метода, он не всегда будет оптимальным, т.к. не принимает в расчет возможность наличия выбросов в исходном множестве и, зачастую, приводит к большому количеству пробелов. Таким образом, хороший алгоритм обобщения должен решать многокритериальную задачу, которая тем или иным образом минимизирует количество элементов обобщения: головных понятий, пробелов и выбросов. Штрафы за наличие этих элементов должны учитывать экспертное мнение исследователя. 

Введем следующие определения:
\begin{itemize*}
	\item $T$ --- направленное корневое дерево, вершины которого аннотированы темами предметной области, а ребра выражают отношение включения.
	\item $I$ --- множество \textit{листьев} дерева $T$.
	\item $\chi(t)$ --- множество детей вершины $t$. Вершина $t$ является \textit{родителем} вершины $t'$, если существует ребро от $t$ к $t'$. Обратно: $t$ --- \textit{ребенок} $t'$, если существует ребро от $t'$ к $t$.
	\item $T(t)$ --- \textit{поддерево} вершины $t$ (сама вершина и все ее потомки).
	\item $I(t)$ --- множество листьев поддерева $T(t), \ t\in T-I$ (\textit{листовой кластер}).
	
	\item $S={u(i)\geq0,\forall i\in I}$ --- \textit{нечеткое множество} на $I$.
	\item $S_u={i\in I: u(i)>0}$ --- \textit{основа} нечеткого множества $S$.
\end{itemize*}

Введем понятия, необходимые для формального определения пробелов, выбросов и головных тем: 
\begin{itemize*}
	\item $t\in T$ называется $u$-\textit{нерелевантной}, если $I(t) \cap S_u=\emptyset$ (т.е. ее листовой кластер не пересекается с основой нечеткого множества).
	Все потомки $t$ так же будут являтся $u$-нерелевантными.
	\item $g\in T(h)\setminus\{h\}$ называется $h$-\textit{пропуском}, если это максимально $u$-нерелевантная вершина (в том смысле, что ее родитель не является $u$-нерелевантным). 
	%%% что-то объяснить!
	\item $G(h)$ --- множество всех $h$-пропусков.
	\item $i\in S_u: i\notin I(h)$ называется $h$-\textit{выбросом} (лист, который не покрыт вершиной $h$).
	\item $S_u -I(h)$ --- множество всех $h$-выбросов.
\end{itemize*}

Т.к. никакая таксономия не может идеально описать все отношения в реальном мире, некоторые нечеткие множества тем могут относиться к более широким понятиям, которые не отражены в используемой таксономии. В этом случае для того, чтобы покрыть все вершины наиболее оптимальным способом, может понадобиться больше одного головных понятия. Исходя из этих соображений, дадим еще несколько определений:

\begin{itemize*}
	\item $H={t\in T}$ называется $u$-\textit{покрытием}, если выполняются следующие условия:
	\begin{enumerate*}
		\item $S_u\subseteq \cup_{h\in H}I(h)$ ($H$ покрывает $S_u$),
		\item $\forall h, h' \in H: h\neq h' \implies I(h)\cap I(h') = \emptyset$ (множества листовых кластеров для любых вершин из $Н$ не пересекаются).
	\end{enumerate*}
	\item $H-I$ --- множество \textit{головных понятий} (внутренних вершин $H$).
	\item $H\cap I$ --- множество \textit{выбросов} (листовых вершин $H$).
	\item $\cup_{h\in H-I}G(h) $  --- множество \textit{пробелов} (объединение множества $h$-пробелов для вершин из $H$).
\end{itemize*}




% ------------------------------------------------------------------------------
\subsection{Критерий наибольшей экономии и метод}
% ------------------------------------------------------------------------------
\subsection{Критерий максимального правдоподобия и метод}


% ==============================================================================
\section{Применение к анализу тенденций в области науки о данных}

% ------------------------------------------------------------------------------
\subsection{Подготовка коллекции текстов}
\label{section:text-data}

В качестве исходных данных были использована коллекция из 68 933 аннотаций научных статей вместе с ключевыми словами, названием журнала и датой публикации. Коллекция были получены следующим способом:
\begin{enumerate*}
	\item Рассматривалось две базы данных журналов: Springer и Elsevier, доступные через электронную библиотеку ВШЭ\footnote{\hrefl{https://library.hse.ru/e-resources}}.
	\item К интерфейсу электронной библиотеки с уточнением категории статей <<компьютерные науки>> были сделаны следующие запросы:
	
	\textsf{clustering, machine learning, neural networks, algorithm, classification, information retrieval, natural language processing, software, computing, pattern recognition, deep learning, probabilistic, artificial intelligence, support vector, bayesian, regression, search engine}, 
	
	\item Все найденные через систему статьи с непустой аннотацией и множеством ключевых словосочетаний загружены специально разработанным краулером.
\end{enumerate*}
Далее была проведена фильтрация коллекции (в скобках приведено количество статей, оставшихся на текущем шаге):
\begin{enumerate*}
	\item Выбраны 80 релевантных тематике наук о данных журналов (26 826).
	\item Удалены статьи, длина аннотации к которым меньше 100 символов (26 799).
\end{enumerate*}
После всех преобразований в коллекции остается 26 799 статей из 80 журналов за период с 1971 по 2019 год. На рисунке \ref{fig:papersdatehist} представлена гистограмма распределения дат публикации статей из коллекции. В таблице \ref{table:papers} представлены 15 журналов с наибольшим количеством публикаций в коллекции. Подробная информация о коллекции представлена в приложении \ref{appendix:journals}.

\begin{figure*}
	\centering
	\includegraphics[width=0.5\linewidth]{images/papers_date_hist}
	\caption{Распределение статей по годам публикации.}
	\label{fig:papersdatehist}
\end{figure*}

\begin{table}
	\def\arraystretch{0.8}
	\centering
	{\small
		\begin{tabular}{lrrl}
			\toprule
			Название журнала                                    &  \# Cтатей     & \# Томов & Период     \\
			\midrule
			Neurocomputing                                      &  3187 &  334 &  1992--2019 \\
			Expert Systems with Applications                    &  2033 &  243 &  1998--2019 \\
			Procedia Computer Science                           &  1933 &  139 &  2010--2019 \\
			Pattern Recognition                                 &  1360 &  301 &  1973--2019 \\
			Applied Soft Computing                              &  1236 &  117 &  2003--2019 \\
			Information Sciences                                &  1211 &  350 &  1998--2019 \\
			Pattern Recognition Letters                         &  1001 &  292 &  1982--2019 \\
			Knowledge-Based Systems                             &  820 &  210 &  1988--2019 \\
			Journal of Systems and Software                     &  760 &  202 &  1998--2019 \\
			IFAC Proceedings Volumes                            &  743 &  280 &  1978--2014 \\
			Information and Software Technology                 &  688 &  236 &  1987--2019 \\
			Neural Networks                                     &  661 &  166 &  1989--2019 \\
			Computational Statistics \& Data Analysis            &  628 &  168 &  1988--2019 \\
			Information Processing \& Management                 &  549 &  121 &  1988--2019 \\
			Engineering Applications of Artificial Intelligence &  500 &  144 &  1992--2019 \\
			\bottomrule
	\end{tabular}}
	\caption{Статистика по 15 журналам издательств Springer и Elsevier с наибольшим количеством публикаций в коллекции.}
	\label{table:papers}
\end{table}

% ------------------------------------------------------------------------------
\subsection{Таксономия наук о данных}

Таксономия --- форма представления знаний об иерархических отношениях внутри некоторой предметной области.

Наиболее известные таксономии разработаны в рамках проекта Gene Onthology project (GO) \cite{gene2018gene}, посвященного созданию унифицированной терминологии для аннотации генов биологических видов и проекта SNOMED CT \cite{lee2013survey}, который представляет собой систематизированную машинно-обрабатываемую медицинскую номенклатуру, которая отражает понятия различных категорий медицины и здравоохранения

Математически таксономия представляется в виде корневого дерева --- ациклического связанного направленного графа, в котором между любыми двумя вершинами существует ровно один путь. Вершины дерева представляет собой различные понятия предметной области. Иерархические отношения отвечают отношениям включения: если вершина A --- родитель вершины B, то понятие B является частным случаем понятия A. Важной характеристикой таксономий является то, что у каждой вершины может быть только один родитель. 

Задача построения таксономий традиционно решалась вручную с помощью экспертных знаний о предметной области \cite{usman2017taxonomies}. Подобный подход имеет несколько недостатков, а именно:
\begin{itemize*}
	\item Таксономия имеет поверхностный характер и не включает в себя множество мелких понятий и тем, которые используются в исследованиях.
	\item Наполнение таксономии происходит медленно, поэтому новые темы включаются в нее с большим запаздыванием.
	\item Экспертная оценка не включает в себя статистический анализ предметной области и может быть смещенной.
\end{itemize*}

Второй подход к созданию таксономий --- автоматическое их построение с помощью тематических коллекций текстов, ключевых слов и т.п. Одним из методов является трехфакторный метод Klink, впервые предложенный в \cite{Osborne2012} группой исследователей под руководством Ф. Осборна, который позволял на основе коллекции ключевых слов научных статей построить таксономию области науки. В дальнейшем на основе этого метода авторы построили полноценную систему для построения онтологий предметной области \cite{Osborne2015} и запустили на основе нее несколько веб-сервисов, позволяющих интерактивно просматривать статистические данные по существующим темам исследований \cite{Salatino2018}, а так же отслеживать изменение и зарождение новых тем \cite{Osborne2013}. Кроме того, авторами предложена система рекомендаций на основе построенной онтологии \cite{Thanapalasingam2018}. Еще один способ автоматического построения таксономий детально описан в \cite{usman2017taxonomies}.

Несмотря на то, что развитие автоматических методов создания таксономий выглядит наиболее перспективно, такой подход обладает рядом недостатков:
\begin{itemize*}
	\item Алгоритмы построения таксономий зависят от большого количества параметров и качество результата однозначно определяется оптимальностью их выбора.
	\item Тщательный подбор параметров по-прежнему требует экспертных знаний предметной области. Таким образом, человеческий фактор, присущий ручным методам построения таксономий, при применении автоматических алгоритмов не исключается.
	\item Полученные таксономии требуют ручной корректировки из-за наличия определенного количества шума: ошибочных связей, нерелевантных вершин, возможного дублирования понятий в разных вершинах.
\end{itemize*}
Более того, таксономии, созданные вручную, несмотря на их недостатки, обычно сочетают в себе как теоретические основы предметной области, так и практический опыт, накопленный людьми, участвовавшими в разработке. Именно поэтому в данной работе принято решение использовать наиболее известную таксономию компьютерных наук ACM Computing Classification System 2012 \cite{associationforcomputingmachinery}, разработанную международной Ассоциацией вычислительной техники (Association for Computing Machinery, ACM). В частности, модифицированное подмножество этой таксономии, связанное с науками о данных и в частности с машинным обучением, дата-майнингом, анализом данных, кластер-анализом и т.д., было использовано в \cite{mirkin2018preprint}. В дополнение к исходной таксономии авторы добавили 68 новых вершин (из которых 60 --- листья), связанных с наиболее современными направлениями исследований. В модифицированной таксономии наук о данных при присутствует 456 вершин, из которых листьями являются 353 вершины. Максимальная глубина таксономии --- 6. Первые два уровня таксономии представлены в таблице \ref{table:acm_higher_ranks}. Полная версия таксономии представлена в приложении \ref{appendix:ds_taxonomy}.
.

\begin{table}
	\def\arraystretch{1.}
	\centering
	\begin{tabular}{|l|l|}
		\hline
		Идентификатор & Заголовок                                             \\
		\hline
		1.             & ~~~~Theory of computation                             \\
		1.1.           & ~~~~~~~~Theory and algorithms for application domains \\
		2.             & ~~~~Mathematics of computing                          \\
		2.1.           & ~~~~~~~~Probability and statistics                    \\
		3.             & ~~~~Information systems                               \\
		3.1.           & ~~~~~~~~Data management systems                       \\
		3.2.           & ~~~~~~~~Information systems applications              \\
		3.3.           & ~~~~~~~~World Wide Web                                \\
		3.4.           & ~~~~~~~~Information retrieval                         \\
		4.             & ~~~~Human-centered computing                          \\
		4.1.           & ~~~~~~~~Visualization                                 \\
		5.             & ~~~~Computing methodologies                           \\
		5.1.           & ~~~~~~~~Artificial intelligence                       \\
		5.2.           & ~~~~~~~~Machine learning                              \\
		\hline
	\end{tabular}
	\label{table:acm_higher_ranks}
	\caption{Первые два уровня модифицированной таксономии наук о данных, основанной на ACM Computing Classification System 2012.}
\end{table}

	
% ------------------------------------------------------------------------------
\subsection{Метод и вычисление матрицы релевантности текст -- словосочетание}

Наиболее популярными методами оценки релевантности тестовых документов к заданному словосочетанию (запросу) являются методы, основанные на непосредственном сравнении строк, либо основанные на сравнении некоторых термов, извлеченных из текстов (словосочетаний, $n$-грамм и т.д.) \cite{gomaa2013survey}. Кроме этого, в последние годы набирают популярность методы, учитывающие не только синтаксическую близость текстов, но и семантическую. В частности, это модели, помещающие все слова языка в некоторое векторно5е пространство большой размерности, где расстояние между словами характеризует их семантическую и смысловую близость. При построении векторного пространства используется как классические статистические методы \cite{Erk_2012}, так и основанные на глубинном обучении \cite{li2018word}.

В данной работе используется метод аннотированного суффиксного дерева, впервые предложенный R.Pampapathi \cite{Pampapathi_2006} в приложении к анти-спам фильтрации электронных писем. Далее метод был развит Е.Черняк и Б.Миркиным в \cite{Chernyak_2015, Chernyak_Mirkin_2015}. Преимуществами данного метода является то, что он не требует серьезной предобработки текстов (стемминга, лемматизации, нормализации и. т.п.) и позволяет оценить релевантность словосочетания (короткой строки) к тексту, основываясь исключительно на данных о частотности и последовательности символов в тексте (без семантического составляющей).

Аннотированное суффиксное дерево (Annotated Suffix Tree, AST) --- это взвешенное корневое дерево, используемое для хранения фрагментов текста и их частотностей в исходном тексте. $k$-суффиксом строки $s=c_1c_2\ldots c_N$ называется фрагмент этой строки $s^k=c_{N-k+1}c_{N-k+2}\ldots c_{N}$. К примеру, 3-суффиксом строки "<information"> является строка "<ion">, а 6-суффиксом является строка "<mation">. Вершины AST отвечают следующим условиям:
\begin{itemize*}
	\item Каждая вершина отвечает одному символу строки.
	\item Каждая вершина аннотирована частотой встречи текстового фрагмента, который закодирован с помощью пути от корня дерева до этой вершины.
	\item Корень дерева не имеет символа и аннотации.
\end{itemize*}

Наивный алгоритм построения AST представлен ниже.

\begin{enumerate*}
	\item Инициализировать AST одной вершиной T (корнем дерева).
	\item Найти все суффиксы заданной строки $s$: $\{s^k=c_{N-k+1}c_{N-k+2}\ldots c_{N}, \ k=1,\ldots, N\}$.
	\item Для каждого суффикса найти максимальный путь из корня, символы вершин на котором совпадают с начальным фрагментом суффикса $s^{k_max}$, после чего аннотированное значение каждой из вершин на этом пути необходимо увеличить на единицу. Если длина пути $k_{max}$ оказывается меньше длины суффикса $k$, то к пути добавляются новые вершины, отвечающие каждому из символов оставшейся части суффикса. Аннотации новых вершин инициализируются единицей.
\end{enumerate*}
Вычислительная сложность такого алгоритма составляет $O(N^2)$. Существуют его более эффективные версии, использующие в качестве структуры данных суффиксные массивы и суффиксные деревья \cite{Grossi_2005}. Модифицированная версия алгоритма позволяет строить AST за время $O(N)$.

После того, как аннотированное суффиксное дерево $T$ с корнем $R$ для текста построено, возникает задача оценки релевантности этого текста к произвольно заданной строке $x$. Авторами в \cite{MirkinChernyak2012} предложен следующий алгоритм:
\begin{enumerate*}
	
	\item  Для каждой вершины $u$ дерева $T$ вычисляется условная вероятность:
	{\sffamily
	\begin{equation}
		p(u)=\begin{cases}
			\displaystyle	\frac{f(u)}{f(\text{parent}(u))}, & \text{parent}(u) \ne R,\\[15pt]
			\displaystyle	\frac{f(u)}{\sum_{v\in T:\ \text{parent}(v)=R}f(v)}, & \text{parent}(u) = R,
		\end{cases}
	\end{equation}
	}
	где $f(u)$ --- аннотация вершины $u$. 
	\item Для каждого $k$-суффикса строки $x$ вычисляется коэффициент его релевантности тексту, хранимому в дереве $T$. 
	\begin{equation}
		s(x^k, T)=\frac{1}{k_{max}}\sum_{i=1}^{k_{max}}p(x_i^k),
	\end{equation}
	\item Релевантность строки $x$ тексту, хранимому в $T$, вычисляется как среднее значение коэффициентов релевантности всех суффиксов строки:
	\begin{equation}
		S(x,T)=\frac1N\sum_{k=1}^{N}s(x^k, T).
	\end{equation}
\end{enumerate*}

На практике вместо построения одного большого аннотированного суффиксного дерева для целого текста, текст разбивают на набор коротких строк, состоящих из 2-5 последовательно идущих слов, после чего по очереди добавляют каждую из строк в AST с помощью алгоритма, описанного выше.

Перед построением AST тексты предобрабатываются следующим образом:
\begin{enumerate*}
	\item Символы текста приводятся к нижнему регистру.
	\item Удаляется пунктуация (символы, не являющиеся пробельными символами, буквами или цифрами).
	\item Для того, чтобы уменьшить влияние наиболее часто встречающихся слов, удаляются стоп-слова\footnote{\hrefl{https://raw.githubusercontent.com/nltk/nltk\_data/gh-pages/packages/corpora/stopwords.zip}}.
	\item Текст разрезается на множество фрагментов по 5 слов.
\end{enumerate*}

После построения AST временная сложность получения оценки релевантности строки к тексту составляет $O(m^2)$, где $m$ --- длина оцениваемой строки.

Таким образом, для получения матрицы релевантности статей к листьям таксономии, необходимо для каждой из аннотаций статей построить AST, после чего для каждого из словосочетаний, привязанных к листьям таксономии, получить оценку его релевантности. Для набора данных, описанного в \ref{section:text-data}, итогом работы алгоритма является матрица действительных чисел $T=(t_{ij})$ размера $26799 \times 353$.

%%% пример работы?

% ------------------------------------------------------------------------------
\subsection{Метод построения таблицы корелевантности словосочетаний}

Схожесть тем (словосочетаний) $i$ и $j$ может быть определена как скалярное произведение векторов $t_i=(t_{vi})$ и $t_j=(t_{vj})$, $v=1,\ldots,26799$, где каждый текст взвешен коэффициентом, отражающим количество тем, релевантных этому тексту. Такая поправка необходима, чтобы придать документам с большим количеством релевантных тем больший вес в скалярном произведении (см. \cite{mirkin2010constructing}).

\begin{equation}
	\begin{gathered}
		w_{v} = \frac{n_v}{\max_{v'} n_{v'}}, \\
		n_v = \#_i[t_{vi} > \alpha]
	\end{gathered}
	\label{eq:rel_wt}
\end{equation}

где $\alpha$ --- порог, определяемый эмпирически (см. \cite{Chernyak_2015}). Для соответствия распределений $n_v$ с \cite{mirkin2018preprint} выбрано значение $\alpha=0.4$. Распределение количества релеватных тем $n_v$ приведено в таблице и на рисунке \ref{fig:relevant_counts}.

C учетом вышесказанного, таблица корелевантности тем определяется следующим образом:
\begin{equation}
	R = (r_{ij}), \  r_{ij} = \sum_{v} w_{v} t_{vi} t_{vj}, \ \ i,j\in[1,\ldots, 353].
	\label{eq:rel}
\end{equation}

Известно (см. \cite{MirkinChernyak2012}), что матрица $R$, определенная уравнениями \eqref{eq:rel} и \eqref{eq:rel_wt}, обладает следующими свойствами:

\begin{itemize*}
	\item $R$ неотрицательно определена.
	\item $r_{ij}>0$ в том случае, если существует хотя бы один текст, к которому релевантны сразу обе темы $i$ и $j$.
	\item Чем больше количество текстов, релевантных темам $i$ и $j$, тем больше значение $r_{ij}$.
\end{itemize*}

\begin{figure}
	\centering
	\caption{Распределение релевантных тем в текстовой коллекции.}
	\label{fig:relevant_counts}
	\begin{minipage}{0.45\textwidth}
		\centering
		\includegraphics[width=0.9\textwidth]{images/relevants_hist}
	\end{minipage}
	\begin{minipage}{0.45\textwidth}
		\centering
		\begin{tabular}{|p{0.45\textwidth}|p{0.45\textwidth}|}
			\hline 
			Количество текстов & Количество релевантных тем \\ 
			\hline 
			2401 (9\%)  & 0 \\ 
			3867 (14\%)   & 1 \\ 
			10868 (41\%)  & 2-4 \\ 
			8921 (33\%)   & 5-11 \\ 
			742 (3\%)    & 12 и более \\ 
			\hline 
		\end{tabular} 
	\end{minipage}
\end{figure}

% ------------------------------------------------------------------------------
\subsection{Метод и кластер-анализ таблицы корелевантности}

Обозначим множество листовых вершин с соответствующими им темами $T$. Нечеткий кластер над $T$ определяется функцией принадлежности $u=(u_t), u_t\in[0,1], t\in T$ и коэффициентом интенсивности $\mu>0$, который связывает значения функции принадлежности с значениями функции схожести. В случае, когда $T$ --- набор тем академических исследований, $u=(u_t), t\in T$ --- кластеры, характеризующие семантическую структуру коллекции текстов, произведение $(\mu u_t)(\mu u_{t'}) = \mu^2u_tu_{t'}$ может рассматриваться как вклад направления исследований, определяемого кластером, в коэффициент корелевантности $r_{tt'}$ между темами $t$ и $t'$. Это предположение согласуется с моделью аддитивной нечеткой кластеризации, предложенной С. Насименто и Б. Миркиным в \cite{mirkin2009analysis}. Утверждается, что элементы матрицы корелевантности тем $R$ могут быть представлены как сумма вкладов $K$ нечетких кластеров, а именно:
\begin{equation}
	r_{tt'}=\sum_{k=1}^{K}\mu_k^2u_{kt}u_{kt'} + \epsilon_{tt'},
	\label{eq:faddis_crit}
\end{equation}
где $\epsilon_{ij}$ --- малые ошибки, $u_k=(u_{kt})$ --- вектор принадлежности $k$-го кластера , $\mu_k$ --- его интенсивность. 

Метод FADDIS, разработанный в \cite{mirkin2009analysis, mirkin2012additive, nascimento2013laplacian}, позволяет с помощью итеративной процедуры извлекать из матрицы схожести нечеткие кластеры согласно критерию \eqref{eq:faddis_crit}. Авторами проведены численные эксперименты, показывающие корректность метода на реальных и синтетических наборах данных.

На каждом шаге работы алгоритма рассматривается задача минимизации критерия наименьших квадратов для одного кластера:

\begin{equation}
	E=\sum_{t,t'\in T}(w_{tt'}-\xi u_t u_{t'})^2,
	\label{eq:faddis_onestep_crit}
\end{equation}
где $W=(w_{tt'})$ --- матрица сходства элементов $t\in T$, а неизвестными параметрами являются $\xi>0$ --- вес кластера и $u=(u_t)$ --- вектор принадлежности элементов $t\in T$ кластеру. Значение интенсивности из \eqref{eq:faddis_crit} определяется как $\mu=\sqrt{\xi}$.

На первом шаге алгоритма в качестве $W$ берется исходная матрица сходства $R$. На втором и последующих шагах $W$ определяется как остаток от вычитания из матрицы сходства на предыдущем шаге вклада кластера, найденного с помощью оптимизации критерия \eqref{eq:faddis_onestep_crit}:

\begin{equation}
	W  \coloneqq W - \mu^2uu^T.
\end{equation}

Каждый элемент матрицы $R$, таким образом, действительно представляет собой сумму вкладов индивидуальных кластеров с точностью до малых ошибок. Количество кластеров $K$ может быть определено как заранее, так и в процессе работы алгоритма согласно некоторому критерию остановки.

Для минимизации целевой функции \eqref{eq:faddis_onestep_crit} относительно $\xi$ при заданном произвольном векторе $u$ продифференцируем ее по $\xi$ и получим необходимое условия существования ее экстремума:

\begin{equation}
	\frac{\partial E}{\partial \xi}= -2\sum_{t,t'\in T}(w_{tt'}-\xi u_t u_{t'}) u_t u_{t'} =0.
\end{equation}
Из этого уравнения получим выражение для оптимального $\xi$:

\begin{equation}
	\xi = \frac{\sum_{t,t'\in T}w_{tt'} u_t u_{t'}}{(\sum_{t \in T}u_t^2)^2},
\end{equation}
В матричном виде:

\begin{equation}
\xi = \frac{u^TWu}{(u^Tu)^2},
\end{equation}
В случае, когда матрица $W$ неотрицательно определена, значение $\xi$ всегда неотрицательно. Подставляя $\xi$ в \eqref{eq:faddis_onestep_crit}, получим:

\begin{equation}
	E = \sum_{t,t'\in T}w_{tt'}^2-\xi^2 \sum_{t\in T}u_t^2 \sum_{t'\in T}u_{t'}^2 = S(W) - G(u)),
\end{equation}
где $S(W)=\sum_{t,t'\in T}w_{tt'}^2$ --- разброс данных, $G(u) = \xi^2 (u^Tu)^2= \left(\frac{u^TWu}{u^Tu}\right)^2$. Таким образом, разброс данных может быть представлен в виде суммы объясненной и необъясненной кластером $u$ частей:
\begin{equation}
	S(W)=G(u)+E.
\end{equation}
И, так как $S(W)$ зависит только от исходной матрицы $W$ и является константой по отношению к $u$, задача минимизации $E$ эквивалентна задаче максимизации $G(u)$ или квадратного корня из этой величины:
\begin{equation}
	g(u)=\sqrt{G(u)} = \frac{u^TWu}{u^Tu}.
	\label{eq:rayleigh}
\end{equation}
Величина  $g(u)$ называется отношением Релэя \cite{parlett1998symmetric}. Для случая безусловной оптимизации известно, что максимум этого отношения равен максимальному собственному значению матрицы $W$ и достигается на соответствующем собственном векторе $z$. Для получения субоптимального решения задачи условной оптимизации с ограничением $u_t\in[0, 1], t\in T$ воспользуемся следующим методом:
\begin{enumerate*}
	\item Получим решение безусловной задачи оптимизации в виде нормализованного собственного вектора $z:\ z^Tz=1$, отвечающего максимальному собственному значению матрицы $W$.
	\item Воспользуемся оператором проекции на множество векторов ${v:\ \forall t\in T\ v_t\in[0, 1]}$:
	\begin{equation}
		v_t =\begin{cases}
		0, & z_t \leq 0,\\
		z_t, & 0<z_t<1\\
		1, & z_t\geq 1.
		\end{cases}
	\end{equation}
	Нужно заметить, что т.к. исходный вектор $z$ нормирован, то третье условие не выполнится никогда и оставлено здесь для большей наглядности.
	\item В выражениях для $\xi, g(u)$ присутствует величина $u^Tu$, поэтому естественным методом нормировки будет $u^Tu=\sum_{t\in T} u_t^2=1$. Нормируем полученный на предыдущем шаге вектор:
	\begin{equation}
		u = \frac{v}{\sqrt{v^Tv}}.
	\end{equation}
\end{enumerate*}

Полученному вектору $u$ отвечает значение веса кластера $\xi=u^TWu$ и значение вклада в разброс данных $G(u)=(u^TWu)^2=\xi^2$. Необходимо заметить, что, так как вектор $-z$ тоже является собственным вектором, отвечающим максимальному собственному значению матрицы $W$, использование в шаге 2 значения $-z_t$ вместо $z_t$ так же ведет к получению корректного вектора $u$. В этом случае в качестве решения следует взять вектор, соответствующий более высокому значению вклада кластера в разброс данных $G(u)$.

Процесс итеративного извлечения кластера останавливается, когда выполняется одно из следующих условий:
\begin{enumerate*}
	\item Значение $\xi$, полученное на текущем шаге, отрицательное.
	\item Вклад извлеченного на данном шаге кластера меньше некоторого порога. К примеру, вклад должен быть больше среднего вклада одного объекта.
	\item Остаточный разброс данных $E$ становится меньше, к примеру, 5\% от начального значения разброса.
	\item Достигнуто заданное заранее количество кластеров.
\end{enumerate*}

Для того, чтобы сделать структуру кластеров в начальных данных более явной, можно применить дискретное нормализованное преобразование Лапласа \cite{von2007tutorial}. Подобное преобразование используется при нахождении субоптимального решения для задачи наименьшего нормализованного разреза (min normalized cut). Известно, что решением этой задачи является собственный вектор, отвечающий наименьшему ненулевому собственному значению преобразованной матрицы смежности графа. Алгоритм FADDIS, в свою очередь, требует нахождения наибольшего собственного значения и отвечающего ему собственного вектора. Именно поэтому в \cite{mirkin2012additive} предложено использовать модифицированое преобразование Лапласа, задействующее обратные собственные значения матрицы смежности. 

Нормализованное преобразование Лапласа для матрицы $W$ определяется следующим образом:
\begin{equation}
	L_n=I-D^{-\frac{1}{2}}WD^{-\frac{1}{2}}, 
\end{equation}
где $I$ --- единичная матрица аналогичного $W$ размера, $D$ --- диагональная матрица, в которой $d_{tt} =\sum_{t'\in T} w_{tt'}$. 
Тогда псевдо-обратным преобразованием Лапласа (Laplacian pseudo-inverse transform, LAPIN) называется следующая матрица:
\begin{equation}
	L_n^+ = Z \tilde{\Lambda} Z^T,
\end{equation}
где $Z$ --- матрица собственных векторов, отвечающих ненулевым собственным значениям матрицы $L_n$ (из ее спектрального разложения --- $L_n=Z\Lambda Z^T$), $\tilde{\Lambda}$ --- матрица, получаемая из матрицы $\Lambda$ удалением нулевых значений на диагонали.

Для решения задачи кластеризации с помощью FADDIS исходная матрица схожести $R$ преобразовывается с помощью LAPIN, после чего применяется описанный выше алгоритм построения нечетких кластеров.

% ------------------------------------------------------------------------------
\subsection{Программное обеспечение}

В результате работы над дипломным проектом был разработан комплекс программ, в том числе:

\begin{itemize*} %%%%%%% TODO
	\item Извлечение информации из сырых текстовых данных, полученных краулером, и предобработка текстов.
	\item AST
	\item Построение матрицы схожести 
	\item LAPIN
	\item FADDIS
	\item Алгоритм экономичного обобщения в таксономии.
\end{itemize*} %%%%%%% TODO

Разработка велась на языке Python версии 3.6.8. Коды программ доступны в репозитории на GitHub. %%%% TODO
Расчеты проводились на личном ноутбуке с процессором Intel Core-i5 и 8 ГБ RAM, а так же на доступных автору вычислительным мощностям (сервер DELL R640).

% ------------------------------------------------------------------------------
\subsection{Результаты расчетов и выводы}

% ==============================================================================
\section{Заключение}


% ==============================================================================

\nocite{*}
\bibliographystyle{ugost2008mod} 
\bibliography{bibliography}

% ==============================================================================
\appendix

\section{Список журналов в коллекции}
\label{appendix:journals}
\begin{center}
	\def\arraystretch{0.8}
	{\small
		\begin{longtable}{lrrl}
			\toprule
			Название журнала                                                                     & \# Cтатей & \# Томов & Период    \\
			\midrule			 
			\endhead
			Neurocomputing                                                                       &      3187 &      334 & 1992-2019 \\
			Expert Systems with Applications                                                     &      2033 &      243 & 1998-2019 \\
			Procedia Computer Science                                                            &      1933 &      139 & 2010-2019 \\
			Pattern Recognition                                                                  &      1360 &      301 & 1973-2019 \\
			Applied Soft Computing                                                               &      1236 &      117 & 2003-2019 \\
			Information Sciences                                                                 &      1211 &      350 & 1998-2019 \\
			Pattern Recognition Letters                                                          &      1001 &      292 & 1982-2019 \\
			Knowledge-Based Systems                                                              &       820 &      210 & 1988-2019 \\
			Journal of Systems and Software                                                      &       760 &      202 & 1998-2019 \\
			IFAC Proceedings Volumes                                                             &       743 &      280 & 1978-2014 \\
			Information and Software Technology                                                  &       688 &      236 & 1987-2019 \\
			Neural Networks                                                                      &       661 &      166 & 1989-2019 \\
			Computational Statistics \& Data Analysis                                            &       628 &      168 & 1988-2019 \\
			Information Processing \& Management                                                 &       549 &      121 & 1988-2019 \\
			Engineering Applications of Artificial Intelligence                                  &       500 &      144 & 1992-2019 \\
			NeuroImage                                                                           &       426 &      191 & 2002-2019 \\
			European Journal of Operational Research                                             &       425 &      244 & 1984-2019 \\
			Journal of Statistical Planning and Inference                                        &       398 &      178 & 1982-2019 \\
			Signal Processing                                                                    &       368 &      133 & 1979-2019 \\
			Physica A: Statistical Mechanics and its Applications                                &       348 &      158 & 1997-2019 \\
			Statistics \& Probability Letters                                                    &       294 &      162 & 1991-2019 \\
			Computers in Biology and Medicine                                                    &       293 &      122 & 1973-2019 \\
			International Journal of Approximate Reasoning                                       &       291 &      117 & 1987-2019 \\
			Journal of Visual Communication and Image Representation                             &       288 &       69 & 2002-2019 \\
			Computer Methods and Programs in Biomedicine                                         &       282 &      127 & 1986-2019 \\
			Journal of Multivariate Analysis                                                     &       275 &      117 & 1998-2019 \\
			Computer Networks                                                                    &       272 &      124 & 1999-2019 \\
			Decision Support Systems                                                             &       236 &      126 & 1985-2019 \\
			Fuzzy Sets and Systems                                                               &       236 &      158 & 1980-2019 \\
			Computers \& Geosciences                                                             &       219 &      111 & 1984-2019 \\
			Computers \& Operations Research                                                     &       202 &       95 & 2000-2019 \\
			Journal of Computational and Applied Mathematics                                     &       195 &       96 & 1995-2019 \\
			Image and Vision Computing                                                           &       194 &      115 & 1983-2019 \\
			Computer Vision and Image Understanding                                              &       187 &       88 & 2002-2019 \\
			Data \& Knowledge Engineering                                                        &       180 &      108 & 1985-2019 \\
			Computers in Human Behavior                                                          &       180 &       80 & 1997-2019 \\
			Swarm and Evolutionary Computation                                                   &       172 &       43 & 2011-2019 \\
			Digital Signal Processing                                                            &       170 &       75 & 2003-2019 \\
			Biomedical Signal Processing and Control                                             &       168 &       50 & 2006-2019 \\
			Information Processing Letters                                                       &       167 &      119 & 1971-2019 \\
			Journal of Network and Computer Applications                                         &       162 &       86 & 2005-2019 \\
			Artificial Intelligence in Medicine                                                  &       157 &      104 & 1989-2019 \\
			Information Systems                                                                  &       156 &       77 & 1987-2019 \\
			Signal Processing: Image Communication                                               &       155 &       69 & 2000-2019 \\
			Artificial Intelligence                                                              &       155 &      101 & 1996-2019 \\
			Computer Speech \& Language                                                          &       153 &       56 & 2004-2019 \\
			Robotics and Autonomous Systems                                                      &       136 &       87 & 1989-2019 \\
			Information Fusion                                                                   &       111 &       49 & 2001-2019 \\
			Medical Image Analysis                                                               &       106 &       50 & 2002-2019 \\
			International Journal of Medical Informatics                                         &       104 &       71 & 1997-2019 \\
			International Journal of Forecasting                                                 &       101 &       42 & 1994-2019 \\
			Ad Hoc Networks                                                                      &        98 &       55 & 2004-2019 \\
			Information \& Management                                                            &        91 &       67 & 1989-2019 \\
			Information and Computation                                                          &        82 &       51 & 2004-2019 \\
			Physics Letters A                                                                    &        81 &       71 & 2000-2019 \\
			Journal of the Korean Statistical Society                                            &        81 &       34 & 2008-2019 \\
			International Journal of Information Management                                      &        76 &       51 & 1999-2019 \\
			Journal of Web Semantics                                                             &        75 &       42 & 2004-2018 \\
			Journal of Mathematical Psychology                                                   &        74 &       44 & 2005-2019 \\
			Computerized Medical Imaging and Graphics                                            &        66 &       39 & 1996-2019 \\
			Computers \& Graphics                                                                &        62 &       42 & 2000-2019 \\
			Computers \& Structures                                                              &        61 &       49 & 2000-2019 \\
			Journal of Symbolic Computation                                                      &        56 &       28 & 2005-2019 \\
			International Journal of Human-Computer Studies                                      &        54 &       46 & 2000-2019 \\
			Journal of Informetrics                                                              &        52 &       26 & 2009-2019 \\
			Statistical Methodology                                                              &        50 &       31 & 2004-2016 \\
			Spatial Statistics                                                                   &        49 &       28 & 2012-2019 \\
			Performance Evaluation                                                               &        49 &       38 & 2000-2019 \\
			Computer Languages, Systems \& Structures                                            &        47 &       28 & 2004-2018 \\
			Biologically Inspired Cognitive Architectures                                        &        47 &       18 & 2013-2018 \\
			Handbook of Statistics                                                               &        42 &       12 & 2005-2019 \\
			Telematics and Informatics                                                           &        39 &       28 & 1997-2019 \\
			Intelligence                                                                         &        39 &       33 & 2001-2019 \\
			Molecular Phylogenetics and Evolution                                                &        35 &       32 & 2005-2019 \\
			Computer Networks and ISDN Systems                                                   &        28 &        8 & 1990-1998 \\
			Econometrics and Statistics                                                          &        28 &        9 & 2017-2019 \\
			Journal of Discrete Algorithms                                                       &        25 &       21 & 2003-2018 \\
			Artificial Intelligence in Engineering                                               &        23 &       15 & 1989-2001 \\
			Applied Computing and Informatics                                                    &        22 &        7 & 2014-2019 \\
			Big Data Research                                                                    &        19 &       11 & 2015-2019 \\
			\bottomrule \\
			\caption{Статистика по всем журналам в коллекции текстов.}
		\end{longtable}
	}
	\end{center}

\section{Таксономия науки о данных, основанная на ACM-CCS 2012}
\label{appendix:ds_taxonomy}

\begin{center}
	\def\arraystretch{0.9}	
	\linespread{0.8}
	
	{\tiny
	\begin{tabularx}{\linewidth}{|c|X|X|X|X|X|X|}		
		\toprule
		Идентификатор & \multicolumn{6}{l}{Заголовок} \\
		&                        Уровень 1 &                                             Уровень 2 &                                            Уровень 3 &                                                      Уровень 4 &                                              Уровень 5 &                                  Уровень 6 \\
		\midrule
		\endhead
		\midrule
		\endfoot
		\bottomrule
		\endlastfoot
		1. &  Theory of computation &   &   &   &   &   \\
		1.1. &   &  Theory and algorithms for application domains &   &   &   &   \\
		1.1.1. &   &   &  Machine learning theory &   &   &   \\
		1.1.1.1. &   &   &   &  Sample complexity and generalization bounds &   &   \\
		1.1.1.2. &   &   &   &  Boolean function learning &   &   \\
		1.1.1.3. &   &   &   &  Unsupervised learning and clustering &   &   \\
		1.1.1.4. &   &   &   &  Kernel methods &   &   \\
		1.1.1.4.1. &   &   &   &   &  Support vector machines &   \\
		1.1.1.4.2. &   &   &   &   &  Gaussian processes &   \\
		1.1.1.4.3. &   &   &   &   &  Modelling &   \\
		1.1.1.5. &   &   &   &  Boosting &   &   \\
		1.1.1.6. &   &   &   &  Bayesian analysis &   &   \\
		1.1.1.7. &   &   &   &  Inductive inference &   &   \\
		1.1.1.8. &   &   &   &  Online learning theory &   &   \\
		1.1.1.9. &   &   &   &  Multi-agent learning &   &   \\
		1.1.1.10. &   &   &   &  Models of learning &   &   \\
		1.1.1.11. &   &   &   &  Query learning &   &   \\
		1.1.1.12. &   &   &   &  Structured prediction &   &   \\
		1.1.1.13. &   &   &   &  Reinforcement learning &   &   \\
		1.1.1.13.1. &   &   &   &   &  Sequential decision making &   \\
		1.1.1.13.2. &   &   &   &   &  Inverse reinforcement learning &   \\
		1.1.1.13.3. &   &   &   &   &  Apprenticeship learning &   \\
		1.1.1.13.4. &   &   &   &   &  Multi-agent reinforcement learning &   \\
		1.1.1.13.5. &   &   &   &   &  Adversarial learning &   \\
		1.1.1.14. &   &   &   &  Active learning &   &   \\
		1.1.1.15. &   &   &   &  Semi-supervised learning &   &   \\
		1.1.1.16. &   &   &   &  Markov decision processes &   &   \\
		1.1.1.17. &   &   &   &  Regret bounds &   &   \\
		1.1.2. &   &   &  Database theory &   &   &   \\
		1.1.2.1. &   &   &   &  Data exchange &   &   \\
		1.1.2.2. &   &   &   &  Data provenance &   &   \\
		1.1.2.3. &   &   &   &  Data modeling &   &   \\
		1.1.2.4. &   &   &   &  Database query languages (principles) &   &   \\
		1.1.2.5. &   &   &   &  Database constraints theory &   &   \\
		1.1.2.6. &   &   &   &  Database interoperability &   &   \\
		1.1.2.7. &   &   &   &  Data structures and algorithms for data management &   &   \\
		1.1.2.8. &   &   &   &  Database query processing and optimization (theory) &   &   \\
		1.1.2.9. &   &   &   &  Data integration &   &   \\
		1.1.2.10. &   &   &   &  Logic and databases &   &   \\
		1.1.2.11. &   &   &   &  Theory of database privacy and security &   &   \\
		1.1.2.12. &   &   &   &  Incomplete, inconsistent, and uncertain databases &   &   \\
		2. &  Mathematics of computing &   &   &   &   &   \\
		2.1. &   &  Probability and statistics &   &   &   &   \\
		2.1.1. &   &   &  Probabilistic representations &   &   &   \\
		2.1.1.1. &   &   &   &  Bayesian networks &   &   \\
		2.1.1.2. &   &   &   &  Markov networks &   &   \\
		2.1.1.3. &   &   &   &  Factor graphs &   &   \\
		2.1.1.4. &   &   &   &  Decision diagrams &   &   \\
		2.1.1.5. &   &   &   &  Equational models &   &   \\
		2.1.1.6. &   &   &   &  Causal networks &   &   \\
		2.1.1.7. &   &   &   &  Stochastic differential equations &   &   \\
		2.1.1.8. &   &   &   &  Nonparametric representations &   &   \\
		2.1.1.8.1. &   &   &   &   &  Kernel density estimators &   \\
		2.1.1.8.2. &   &   &   &   &  Spline models &   \\
		2.1.1.8.3. &   &   &   &   &  Bayesian nonparametric models &   \\
		2.1.2. &   &   &  Probabilistic inference problems &   &   &   \\
		2.1.2.1. &   &   &   &  Maximum likelihood estimation &   &   \\
		2.1.2.2. &   &   &   &  Bayesian computation &   &   \\
		2.1.2.3. &   &   &   &  Computing most probable explanation &   &   \\
		2.1.2.4. &   &   &   &  Hypothesis testing and confidence interval computation &   &   \\
		2.1.2.5. &   &   &   &  Density estimation &   &   \\
		2.1.2.5.1. &   &   &   &   &  Quantile regression &   \\
		2.1.2.6. &   &   &   &  Max marginal computation &   &   \\
		2.1.3. &   &   &  Probabilistic reasoning algorithms &   &   &   \\
		2.1.3.1. &   &   &   &  Variable elimination &   &   \\
		2.1.3.2. &   &   &   &  Loopy belief propagation &   &   \\
		2.1.3.3. &   &   &   &  Variational methods &   &   \\
		2.1.3.4. &   &   &   &  Expectation maximization &   &   \\
		2.1.3.5. &   &   &   &  Markov-chain Monte Carlo methods &   &   \\
		2.1.3.5.1. &   &   &   &   &  Gibbs sampling &   \\
		2.1.3.5.2. &   &   &   &   &  Metropolis-Hastings algorithm &   \\
		2.1.3.5.3. &   &   &   &   &  Simulated annealing &   \\
		2.1.3.5.4. &   &   &   &   &  Markov-chain Monte Carlo convergence measures &   \\
		2.1.3.6. &   &   &   &  Sequential Monte Carlo methods &   &   \\
		2.1.3.7. &   &   &   &  Kalman filters and hidden Markov models &   &   \\
		2.1.3.7.1 &   &   &   &   &  Factorial HMM &   \\
		2.1.3.8. &   &   &   &  Resampling methods &   &   \\
		2.1.3.8.1. &   &   &   &   &  Bootstrapping &   \\
		2.1.3.8.2. &   &   &   &   &  Jackknifing &   \\
		2.1.3.9. &   &   &   &  Random number generation &   &   \\
		2.1.4. &   &   &  Probabilistic algorithms &   &   &   \\
		2.1.5. &   &   &  Statistical paradigms &   &   &   \\
		2.1.5.1. &   &   &   &  Queueing theory &   &   \\
		2.1.5.2. &   &   &   &  Contingency table analysis &   &   \\
		2.1.5.3. &   &   &   &  Regression analysis &   &   \\
		2.1.5.3.1. &   &   &   &   &  Robust regression &   \\
		2.1.5.4. &   &   &   &  Time series analysis &   &   \\
		2.1.5.5. &   &   &   &  Survival analysis &   &   \\
		2.1.5.6. &   &   &   &  Renewal theory &   &   \\
		2.1.5.7. &   &   &   &  Dimensionality reduction &   &   \\
		2.1.5.8. &   &   &   &  Cluster analysis &   &   \\
		2.1.5.9. &   &   &   &  Statistical graphics &   &   \\
		2.1.5.10. &   &   &   &  Exploratory data analysis &   &   \\
		2.1.6. &   &   &  Stochastic processes &   &   &   \\
		2.1.6.1. &   &   &   &  Markov processes &   &   \\
		2.1.7. &   &   &  Nonparametric statistics &   &   &   \\
		2.1.8. &   &   &  Distribution functions &   &   &   \\
		2.1.9. &   &   &  Multivariate statistics &   &   &   \\
		3. &  Information systems &   &   &   &   &   \\
		3.1. &   &  Data management systems &   &   &   &   \\
		3.1.1. &   &   &  Database design and models &   &   &   \\
		3.1.1.1. &   &   &   &  Relational database model &   &   \\
		3.1.1.2. &   &   &   &  Entity relationship models &   &   \\
		3.1.1.3. &   &   &   &  Graph-based database models &   &   \\
		3.1.1.3.1. &   &   &   &   &  Hierarchical data models &   \\
		3.1.1.3.2. &   &   &   &   &  Network data models &   \\
		3.1.1.4. &   &   &   &  Physical data models &   &   \\
		3.1.1.5. &   &   &   &  Data model extensions &   &   \\
		3.1.1.5.1. &   &   &   &   &  Semi-structured data &   \\
		3.1.1.5.2. &   &   &   &   &  Data streams &   \\
		3.1.1.5.3. &   &   &   &   &  Data provenance &   \\
		3.1.1.5.4. &   &   &   &   &  Incomplete data &   \\
		3.1.1.5.5. &   &   &   &   &  Temporal data &   \\
		3.1.1.5.6. &   &   &   &   &  Uncertainty &   \\
		3.1.1.5.7. &   &   &   &   &  Inconsistent data &   \\
		3.1.2. &   &   &  Data structures &   &   &   \\
		3.1.2.1. &   &   &   &  Data access methods &   &   \\
		3.1.2.1.1. &   &   &   &   &  Multidimensional range search &   \\
		3.1.2.1.2. &   &   &   &   &  Data scans &   \\
		3.1.2.1.3. &   &   &   &   &  Point lookups &   \\
		3.1.2.1.4. &   &   &   &   &  Unidimensional range search &   \\
		3.1.2.1.5. &   &   &   &   &  Proximity search &   \\
		3.1.2.2. &   &   &   &  Data layout &   &   \\
		3.1.2.2.1. &   &   &   &   &  Data compression &   \\
		3.1.2.2.2. &   &   &   &   &  Data encryption &   \\
		3.1.2.2.3. &   &   &   &   &  Record and block layout &   \\
		3.1.3. &   &   &  Database management system engines &   &   &   \\
		3.1.3.1. &   &   &   &  DBMS engine architectures &   &   \\
		3.1.3.2. &   &   &   &  Database query processing &   &   \\
		3.1.3.2.1. &   &   &   &   &  Query optimization &   \\
		3.1.3.2.2. &   &   &   &   &  Query operators &   \\
		3.1.3.2.3. &   &   &   &   &  Query planning &   \\
		3.1.3.2.3. &   &   &   &   &  Join algorithms &   \\
		3.1.3.3. &   &   &   &  Database transaction processing &   &   \\
		3.1.3.3.1. &   &   &   &   &  Data locking &   \\
		3.1.3.3.2. &   &   &   &   &  Transaction logging &   \\
		3.1.3.3.3. &   &   &   &   &  Database recovery &   \\
		3.1.3.4. &   &   &   &  Record and buffer management &   &   \\
		3.1.3.5. &   &   &   &  Parallel and distributed DBMSs &   &   \\
		3.1.3.5.1. &   &   &   &   &  Key-value stores &   \\
		3.1.3.5.2. &   &   &   &   &  MapReduce-based systems &   \\
		3.1.3.5.3. &   &   &   &   &  Relational parallel and distributed DBMSs &   \\
		3.1.3.6. &   &   &   &  Triggers and rules &   &   \\
		3.1.3.7. &   &   &   &  Database views &   &   \\
		3.1.3.8. &   &   &   &  Integrity checking &   &   \\
		3.1.3.9. &   &   &   &  Distributed database transactions &   &   \\
		3.1.3.9.1. &   &   &   &   &  Distributed data locking &   \\
		3.1.3.9.2. &   &   &   &   &  Deadlocks &   \\
		3.1.3.9.3. &   &   &   &   &  Distributed database recovery &   \\
		3.1.3.10. &   &   &   &  Main memory engines &   &   \\
		3.1.3.11. &   &   &   &  Online analytical processing engines &   &   \\
		3.1.3.12. &   &   &   &  Stream management &   &   \\
		3.1.4. &   &   &  Query languages &   &   &   \\
		3.1.4.1. &   &   &   &  Relational database query languages &   &   \\
		3.1.4.1.1. &   &   &   &   &  Structured Query Language &   \\
		3.1.4.2. &   &   &   &  XML query languages &   &   \\
		3.1.4.2.1 &   &   &   &   &  XPath &   \\
		3.1.4.2.2. &   &   &   &   &  XQuery &   \\
		3.1.4.3. &   &   &   &  Query languages for non-relational engines &   &   \\
		3.1.4.3.1. &   &   &   &   &  MapReduce languages &   \\
		3.1.4.4. &   &   &   &  Call level interfaces &   &   \\
		3.1.5. &   &   &  Information integration &   &   &   \\
		3.1.5.1. &   &   &   &  Deduplication &   &   \\
		3.1.5.2. &   &   &   &  Extraction, transformation and loading &   &   \\
		3.1.5.3. &   &   &   &  Data exchange &   &   \\
		3.1.5.4. &   &   &   &  Data cleaning &   &   \\
		3.1.5.5. &   &   &   &  Wrappers (data mining) &   &   \\
		3.1.5.6. &   &   &   &  Mediators and data integration &   &   \\
		3.1.5.7. &   &   &   &  Entity resolution &   &   \\
		3.1.5.8. &   &   &   &  Data warehouses &   &   \\
		3.1.5.9. &   &   &   &  Federated databases &   &   \\
		3.2. &   &  Information systems applications &   &   &   &   \\
		3.2.1. &   &   &  Data mining &   &   &   \\
		3.2.1.1. &   &   &   &  Data cleaning &   &   \\
		3.2.1.2. &   &   &   &  Collaborative filtering &   &   \\
		3.2.1.2.1 &   &   &   &   &  Item-based &   \\
		3.2.1.2.2 &   &   &   &   &  Scalable &   \\
		3.2.1.3. &   &   &   &  Association rules &   &   \\
		3.2.1.3.1 &   &   &   &   &  Types of association rules &   \\
		3.2.1.3.2 &   &   &   &   &  Interestingness &   \\
		3.2.1.3.3 &   &   &   &   &  Parallel computation &   \\
		3.2.1.4. &   &   &   &  Clustering &   &   \\
		3.2.1.4.1 &   &   &   &   &  Massive data clustering &   \\
		3.2.1.4.2 &   &   &   &   &  Consensus clustering &   \\
		3.2.1.4.3 &   &   &   &   &  Fuzzy clustering &   \\
		3.2.1.4.4 &   &   &   &   &  Additive clustering &   \\
		3.2.1.4.5 &   &   &   &   &  Feature weight clustering &   \\
		3.2.1.4.6 &   &   &   &   &  Conceptual clustering &   \\
		3.2.1.4.7 &   &   &   &   &  Biclustering &   \\
		3.2.1.5. &   &   &   &  Nearest-neighbor search &   &   \\
		3.2.1.6. &   &   &   &  Data stream mining &   &   \\
		3.2.1.7 &   &   &   &  Graph mining &   &   \\
		3.2.1.7.1 &   &   &   &   &  Graph partitioning &   \\
		3.2.1.7.2 &   &   &   &   &  Frequent graph mining &   \\
		3.2.1.7.3 &   &   &   &   &  Graph based conceptual clustering &   \\
		3.2.1.7.4 &   &   &   &   &  Anomaly detection &   \\
		3.2.1.7.5 &   &   &   &   &  Critical nodes detection &   \\
		3.2.1.8. &   &   &   &  Process mining &   &   \\
		3.2.1.11 &   &   &   &  Text mining &   &   \\
		3.2.1.11.1 &   &   &   &   &  Text categorization &   \\
		3.2.1.11.2 &   &   &   &   &  Key-phrase indexing &   \\
		3.2.1.10. &   &   &   &  Data mining tools &   &   \\
		3.2.1.9 &   &   &   &  Sequence mining &   &   \\
		3.2.1.9.1. &   &   &   &   &  Rule and pattern discovery &   \\
		3.2.1.9.2. &   &   &   &   &  Trajectory clustering &   \\
		3.2.1.9.3 &   &   &   &   &  Market graph &   \\
		3.2.1.12 &   &   &   &  Formal concept analysis &   &   \\
		3.3. &   &  World Wide Web &   &   &   &   \\
		3.3.1. &   &   &  Web mining &   &   &   \\
		3.3.1.2. &   &   &   &  Site wrapping &   &   \\
		3.3.1.3. &   &   &   &  Data extraction and integration &   &   \\
		3.3.1.3.1 &   &   &   &   &  Deep web &   \\
		3.3.1.3.2. &   &   &   &   &  Surfacing &   \\
		3.3.1.3.3. &   &   &   &   &  Search results deduplication &   \\
		3.3.1.4. &   &   &   &  Web log analysis &   &   \\
		3.3.1.5. &   &   &   &  Traffic analysis &   &   \\
		3.3.1.6 &   &   &   &  Knowledge discovery &   &   \\
		3.4. &   &  Information retrieval &   &   &   &   \\
		3.4.1. &   &   &  Document representation &   &   &   \\
		3.4.1.1. &   &   &   &  Document structure &   &   \\
		3.4.1.2. &   &   &   &  Document topic models &   &   \\
		3.4.1.3. &   &   &   &  Content analysis and feature selection &   &   \\
		3.4.1.4. &   &   &   &  Data encoding and canonicalization &   &   \\
		3.4.1.5. &   &   &   &  Document collection models &   &   \\
		3.4.1.6. &   &   &   &  Ontologies &   &   \\
		3.4.1.7. &   &   &   &  Dictionaries &   &   \\
		3.4.1.8. &   &   &   &  Thesauri &   &   \\
		3.4.2. &   &   &  Information retrieval query processing &   &   &   \\
		3.4.2.1. &   &   &   &  Query representation &   &   \\
		3.4.2.2. &   &   &   &  Query intent &   &   \\
		3.4.2.3. &   &   &   &  Query log analysis &   &   \\
		3.4.2.4. &   &   &   &  Query suggestion &   &   \\
		3.4.2.5. &   &   &   &  Query reformulation &   &   \\
		3.4.3. &   &   &  Users and interactive retrieval &   &   &   \\
		3.4.3.1. &   &   &   &  Personalization &   &   \\
		3.4.3.2. &   &   &   &  Task models &   &   \\
		3.4.3.3. &   &   &   &  Search interfaces &   &   \\
		3.4.3.4. &   &   &   &  Collaborative search &   &   \\
		3.4.4. &   &   &  Retrieval models and ranking &   &   &   \\
		3.4.4.1. &   &   &   &  Rank aggregation &   &   \\
		3.4.4.2. &   &   &   &  Probabilistic retrieval models &   &   \\
		3.4.4.3. &   &   &   &  Language models &   &   \\
		3.4.4.4. &   &   &   &  Similarity measures &   &   \\
		3.4.4.5. &   &   &   &  Learning to rank &   &   \\
		3.4.4.6. &   &   &   &  Combination, fusion and federated search &   &   \\
		3.4.4.7. &   &   &   &  Information retrieval diversity &   &   \\
		3.4.4.8. &   &   &   &  Top-k retrieval in databases &   &   \\
		3.4.4.9. &   &   &   &  Novelty in information retrieval &   &   \\
		3.4.5. &   &   &  Retrieval tasks and goals &   &   &   \\
		3.4.5.1. &   &   &   &  Question answering &   &   \\
		3.4.5.2. &   &   &   &  Document filtering &   &   \\
		3.4.5.3. &   &   &   &  Recommender systems &   &   \\
		3.4.5.4. &   &   &   &  Information extraction &   &   \\
		3.4.5.5. &   &   &   &  Sentiment analysis &   &   \\
		3.4.5.6. &   &   &   &  Expert search &   &   \\
		3.4.5.7. &   &   &   &  Near-duplicate and plagiarism detection &   &   \\
		3.4.5.8. &   &   &   &  Clustering and classification &   &   \\
		3.4.5.9. &   &   &   &  Summarization &   &   \\
		3.4.5.10. &   &   &   &  Business intelligence &   &   \\
		3.4.6. &   &   &  Evaluation of retrieval results &   &   &   \\
		3.4.6.1. &   &   &   &  Test collections &   &   \\
		3.4.6.2. &   &   &   &  Relevance assessment &   &   \\
		3.4.6.3. &   &   &   &  Retrieval effectiveness &   &   \\
		3.4.6.4. &   &   &   &  Retrieval efficiency &   &   \\
		3.4.6.5. &   &   &   &  Presentation of retrieval results &   &   \\
		3.4.7. &   &   &  Specialized information retrieval &   &   &   \\
		3.4.7.1. &   &   &   &  Structure and multilingual text search &   &   \\
		3.4.7.1.1. &   &   &   &   &  Structured text search &   \\
		3.4.7.1.2. &   &   &   &   &  Mathematics retrieval &   \\
		3.4.7.1.3. &   &   &   &   &  Chemical and biochemical retrieval &   \\
		3.4.7.1.4. &   &   &   &   &  Multilingual and cross-lingual retrieval &   \\
		3.4.7.2. &   &   &   &  Multimedia and multimodal retrieval &   &   \\
		3.4.7.2.1. &   &   &   &   &  Image search &   \\
		3.4.7.2.2. &   &   &   &   &  Video search &   \\
		3.4.7.2.3. &   &   &   &   &  Speech / audio search &   \\
		3.4.7.2.4. &   &   &   &   &  Music retrieval &   \\
		3.4.7.3. &   &   &   &  Environment-specific retrieval &   &   \\
		3.4.7.3.1. &   &   &   &   &  Enterprise search &   \\
		3.4.7.3.2. &   &   &   &   &  Desktop search &   \\
		3.4.7.3.3. &   &   &   &   &  Web and social media search &   \\
		4. &  Human-centered computing &   &   &   &   &   \\
		4.1. &   &  Visualization &   &   &   &   \\
		4.1.2. &   &   &  Visualization techniques &   &   &   \\
		4.1.2.1. &   &   &   &  Treemaps &   &   \\
		4.1.2.2. &   &   &   &  Hyperbolic trees &   &   \\
		4.1.2.3. &   &   &   &  Heat maps &   &   \\
		4.1.2.4. &   &   &   &  Graph drawings &   &   \\
		4.1.2.5. &   &   &   &  Dendrograms &   &   \\
		4.1.2.6. &   &   &   &  Cladograms &   &   \\
		4.1.2.7 &   &   &   &  Elastic maps &   &   \\
		4.1.3. &   &   &  Visualization application domains &   &   &   \\
		4.1.3.1. &   &   &   &  Scientific visualization &   &   \\
		4.1.3.2. &   &   &   &  Visual analytics &   &   \\
		4.1.3.3. &   &   &   &  Geographic visualization &   &   \\
		4.1.3.4. &   &   &   &  Information visualization &   &   \\
		4.1.4. &   &   &  Visualization systems and tools &   &   &   \\
		4.1.4.1. &   &   &   &  Visualization toolkits &   &   \\
		4.1.5. &   &   &  Visualization theory, concepts and paradigms &   &   &   \\
		4.1.6. &   &   &  Empirical studies in visualization &   &   &   \\
		4.1.7. &   &   &  Visualization design and evaluation methods &   &   &   \\
		5. &  Computing methodologies &   &   &   &   &   \\
		5.1. &   &  Artificial intelligence &   &   &   &   \\
		5.1.1. &   &   &  Natural language processing &   &   &   \\
		5.1.1.2. &   &   &   &  Information extraction &   &   \\
		5.1.1.3. &   &   &   &  Machine translation &   &   \\
		5.1.1.4. &   &   &   &  Discourse, dialogue and pragmatics &   &   \\
		5.1.1.5. &   &   &   &  Natural language generation &   &   \\
		5.1.1.6. &   &   &   &  Speech recognition &   &   \\
		5.1.1.7. &   &   &   &  Lexical semantics &   &   \\
		5.1.1.7.1 &   &   &   &   &  Wikipedia based semantics &   \\
		5.1.1.8. &   &   &   &  Phonology / morphology &   &   \\
		5.1.1.9. &   &   &   &  Language resources &   &   \\
		5.1.2. &   &   &  Knowledge representation and reasoning &   &   &   \\
		5.1.2.1. &   &   &   &  Description logics &   &   \\
		5.1.2.2. &   &   &   &  Semantic networks &   &   \\
		5.1.2.3. &   &   &   &  Nonmonotonic, default reasoning and belief revision &   &   \\
		5.1.2.4. &   &   &   &  Probabilistic reasoning &   &   \\
		5.1.2.5. &   &   &   &  Vagueness and fuzzy logic &   &   \\
		5.1.2.6. &   &   &   &  Causal reasoning and diagnostics &   &   \\
		5.1.2.7. &   &   &   &  Temporal reasoning &   &   \\
		5.1.2.8. &   &   &   &  Cognitive robotics &   &   \\
		5.1.2.9. &   &   &   &  Ontology engineering &   &   \\
		5.1.2.10. &   &   &   &  Logic programming and answer set programming &   &   \\
		5.1.2.11. &   &   &   &  Spatial and physical reasoning &   &   \\
		5.1.2.12. &   &   &   &  Reasoning about belief and knowledge &   &   \\
		5.1.3. &   &   &  Computer vision &   &   &   \\
		5.1.3.1. &   &   &   &  Computer vision problems &   &   \\
		5.1.3.1.1. &   &   &   &   &  Interest point and salient region detections &   \\
		5.1.3.1.2. &   &   &   &   &  Image segmentation &   \\
		5.1.3.1.3. &   &   &   &   &  Video segmentation &   \\
		5.1.3.1.4. &   &   &   &   &  Shape inference &   \\
		5.1.3.1.5. &   &   &   &   &  Object detection &   \\
		5.1.3.1.6. &   &   &   &   &  Object recognition &   \\
		5.1.3.1.7. &   &   &   &   &  Object identification &   \\
		5.1.3.1.8. &   &   &   &   &  Tracking &   \\
		5.1.3.1.9. &   &   &   &   &  Reconstruction &   \\
		5.1.3.1.10. &   &   &   &   &  Matching &   \\
		5.1.3.2. &   &   &   &  Computer vision representations &   &   \\
		5.1.3.2.1. &   &   &   &   &  Image representations &   \\
		5.1.3.2.1.1 &   &   &   &   &   &  2D PCA \\
		5.1.3.2.2. &   &   &   &   &  Shape representations &   \\
		5.1.3.2.3. &   &   &   &   &  Appearance and texture representations &   \\
		5.1.3.2.4. &   &   &   &   &  Hierarchical representations &   \\
		5.2. &   &  Machine learning &   &   &   &   \\
		5.2.1. &   &   &  Learning paradigms &   &   &   \\
		5.2.1.1. &   &   &   &  Supervised learning &   &   \\
		5.2.1.1.1. &   &   &   &   &  Ranking &   \\
		5.2.1.1.2. &   &   &   &   &  Learning to rank &   \\
		5.2.1.1.3. &   &   &   &   &  Supervised learning by classification &   \\
		5.2.1.1.4. &   &   &   &   &  Supervised learning by regression &   \\
		5.2.1.1.5. &   &   &   &   &  Structured outputs &   \\
		5.2.1.1.6. &   &   &   &   &  Cost-sensitive learning &   \\
		5.2.1.2. &   &   &   &  Unsupervised learning &   &   \\
		5.2.1.2.1. &   &   &   &   &  Cluster analysis &   \\
		5.2.1.2.2. &   &   &   &   &  Anomaly detection &   \\
		5.2.1.2.3. &   &   &   &   &  Mixture modeling &   \\
		5.2.1.2.4. &   &   &   &   &  Topic modeling &   \\
		5.2.1.2.5. &   &   &   &   &  Source separation &   \\
		5.2.1.2.6. &   &   &   &   &  Motif discovery &   \\
		5.2.1.2.7. &   &   &   &   &  Dimensionality reduction and manifold learning &   \\
		5.2.1.2.7.1 &   &   &   &   &   &  Graph embedding \\
		5.2.1.2.7.2 &   &   &   &   &   &  Supervised dimesionality reduction \\
		5.2.1.3. &   &   &   &  Reinforcement learning &   &   \\
		5.2.1.3.1. &   &   &   &   &  Sequential decision making &   \\
		5.2.1.3.2. &   &   &   &   &  Inverse reinforcement learning &   \\
		5.2.1.3.3. &   &   &   &   &  Apprenticeship learning &   \\
		5.2.1.3.4. &   &   &   &   &  Multi-agent reinforcement learning &   \\
		5.2.1.3.5. &   &   &   &   &  Adversarial learning &   \\
		5.2.1.4. &   &   &   &  Multi-task learning &   &   \\
		5.2.1.4.1. &   &   &   &   &  Transfer learning &   \\
		5.2.1.4.2. &   &   &   &   &  Lifelong machine learning &   \\
		5.2.1.4.3. &   &   &   &   &  Learning under covariate shift &   \\
		5.2.2. &   &   &  Learning settings &   &   &   \\
		5.2.2.1. &   &   &   &  Batch learning &   &   \\
		5.2.2.2. &   &   &   &  Online learning settings &   &   \\
		5.2.2.3. &   &   &   &  Learning from demonstrations &   &   \\
		5.2.2.4. &   &   &   &  Learning from critiques &   &   \\
		5.2.2.5. &   &   &   &  Learning from implicit feedback &   &   \\
		5.2.2.6. &   &   &   &  Active learning settings &   &   \\
		5.2.2.7. &   &   &   &  Semi-supervised learning settings &   &   \\
		5.2.2.7.1 &   &   &   &   &  Kernel approach &   \\
		5.2.3. &   &   &  Machine learning approaches &   &   &   \\
		5.2.3.1. &   &   &   &  Classification and regression trees &   &   \\
		5.2.3.1.1 &   &   &   &   &  Parallel implementation &   \\
		5.2.3.1.2 &   &   &   &   &  Splittting criteria &   \\
		5.2.3.1.3 &   &   &   &   &  Model trees &   \\
		5.2.3.2. &   &   &   &  Kernel methods &   &   \\
		5.2.3.2.1. &   &   &   &   &  Kernel support vector machines &   \\
		5.2.3.2.1.1 &   &   &   &   &   &  Dynamic \\
		5.2.3.2.2. &   &   &   &   &  Gaussian processes &   \\
		5.2.3.2.3 &   &   &   &   &  Kernel Matrix &   \\
		5.2.3.2.4 &   &   &   &   &  Kernel Independent components &   \\
		5.2.3.2.5 &   &   &   &   &  Kernel-based clustering &   \\
		5.2.3.3. &   &   &   &  Neural networks &   &   \\
		5.2.3.3.1 &   &   &   &   &  Self organized map &   \\
		5.2.3.3.2 &   &   &   &   &  Training approaches &   \\
		5.2.3.3.2.1 &   &   &   &   &   &  Evolutionary approach \\
		5.2.3.3.3 &   &   &   &   &  Representation &   \\
		5.2.3.3.3.1 &   &   &   &   &   &  Rule-based netwok archirtecture \\
		5.2.3.3.3.2 &   &   &   &   &   &  Fuzzy representation \\
		5.2.3.3.4 &   &   &   &   &  Evolving NN &   \\
		5.2.3.3.5 &   &   &   &   &  Ensembling &   \\
		5.2.3.4. &   &   &   &  Logical and relational learning &   &   \\
		5.2.3.4.1. &   &   &   &   &  Inductive logic learning &   \\
		5.2.3.4.2. &   &   &   &   &  Statistical relational learning &   \\
		5.2.3.5. &   &   &   &  Learning in probabilistic graphical models &   &   \\
		5.2.3.5.1. &   &   &   &   &  Maximum likelihood modeling &   \\
		5.2.3.5.2. &   &   &   &   &  Maximum entropy modeling &   \\
		5.2.3.5.3. &   &   &   &   &  Maximum a posteriori modeling &   \\
		5.2.3.5.4. &   &   &   &   &  Mixture models &   \\
		5.2.3.5.5. &   &   &   &   &  Latent variable models &   \\
		5.2.3.5.6. &   &   &   &   &  Bayesian network models &   \\
		5.2.3.5.7. &   &   &   &   &  Markov network models &   \\
		5.2.3.6. &   &   &   &  Learning linear models &   &   \\
		5.2.3.6.1. &   &   &   &   &  Perceptron algorithm &   \\
		5.2.3.6.2 &   &   &   &   &  Linear Discriminant Analysis &   \\
		5.2.3.6.2.1 &   &   &   &   &   &  Tensor representation \\
		5.2.3.7. &   &   &   &  Factorization methods &   &   \\
		5.2.3.7.1. &   &   &   &   &  Non-negative matrix factorization &   \\
		5.2.3.7.2. &   &   &   &   &  Factor analysis &   \\
		5.2.3.7.3. &   &   &   &   &  Principal component analysis &   \\
		5.2.3.7.3.1 &   &   &   &   &   &  2D PCA \\
		5.2.3.7.3.2 &   &   &   &   &   &  Sparse PCA \\
		5.2.3.7.4. &   &   &   &   &  Canonical correlation analysis &   \\
		5.2.3.7.6. &   &   &   &   &  Latent Dirichlet allocation &   \\
		5.2.3.7.8. &   &   &   &   &  Independent Component Analysis &   \\
		5.2.3.7.9 &   &   &   &   &  Nonlinear Principal Components &   \\
		5.2.3.7.10 &   &   &   &   &  Multidimentional scaling &   \\
		5.2.3.7.10.1 &   &   &   &   &   &  Least moduli \\
		5.2.3.8. &   &   &   &  Rule learning &   &   \\
		5.2.3.8.1 &   &   &   &   &  Neuro-fuzzy approach &   \\
		5.2.3.9. &   &   &   &  Instance-based learning &   &   \\
		5.2.3.10. &   &   &   &  Markov decision processes &   &   \\
		5.2.3.11. &   &   &   &  Partially-observable Markov decision processes &   &   \\
		5.2.3.12. &   &   &   &  Stochastic games &   &   \\
		5.2.3.13. &   &   &   &  Learning latent representations &   &   \\
		5.2.3.13.1. &   &   &   &   &  Deep belief networks &   \\
		5.2.3.14 &   &   &   &  Multiresolution &   &   \\
		5.2.3.15 &   &   &   &  Support vector machines &   &   \\
		5.2.4. &   &   &  Machine learning algorithms &   &   &   \\
		5.2.4.1. &   &   &   &  Dynamic programming for Markov decision processes &   &   \\
		5.2.4.1.1. &   &   &   &   &  Value iteration &   \\
		5.2.4.1.2. &   &   &   &   &  Q-learning &   \\
		5.2.4.1.3. &   &   &   &   &  Policy iteration &   \\
		5.2.4.1.4. &   &   &   &   &  Temporal difference learning &   \\
		5.2.4.1.5. &   &   &   &   &  Approximate dynamic programming methods &   \\
		5.2.4.2. &   &   &   &  Ensemble methods &   &   \\
		5.2.4.2.1. &   &   &   &   &  Boosting &   \\
		5.2.4.2.2. &   &   &   &   &  Bagging &   \\
		5.2.4.2.3. &   &   &   &   &  Fusion of classifiers &   \\
		5.2.4.3. &   &   &   &  Spectral methods &   &   \\
		5.2.4.3.1 &   &   &   &   &  Spectral clustering &   \\
		5.2.4.4. &   &   &   &  Feature selection &   &   \\
		5.2.4.5. &   &   &   &  Regularization &   &   \\
		5.2.4.5.1 &   &   &   &   &  Generalized eigenvalue &   \\
		5.2.5. &   &   &  Cross-validation &   &   &   \\
	\end{tabularx}	}

\end{center}


\end{document}

